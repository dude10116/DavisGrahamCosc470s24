{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dude10116/DavisGrahamCosc470s24/blob/main/Davis_Graham_FastNeuralNetwork_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Hello, world** of neural networks\n",
        "This code builds a simple neural network that can recognize handwritten 28x28 pixel digits.\n",
        "\n",
        "Our first version will have 15 neurons in the hidden layer and 10 output neurons.\n",
        "\n",
        "See image below:\n",
        "http://neuralnetworksanddeeplearning.com/images/tikz12.png\n",
        "\n",
        "How many weights in this network?\n",
        "11760 weights in the first layer (784 * 15) and 150 weights in the second layer (15 * 10) = 11910 weights total\n",
        "15 biases in the hidden layer and 10 biases in the output layer = 25 biases total.\n",
        "11910 + 25 = 11935 parameters!"
      ],
      "metadata": {
        "id": "X6OTVSJZLxzO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQQ0yjJ6LUBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0359ae5-b0d6-4c85-9e00-b54d5eb8ce32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nn'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 63 (delta 1), reused 3 (delta 0), pack-reused 55\u001b[K\n",
            "Receiving objects: 100% (63/63), 16.43 MiB | 16.96 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "/content/nn\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MichalDanielDobrzanski/DeepLearningPython nn\n",
        "%cd nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code depends on having executed the previous cell\n",
        "# (i.e., you need to have cloned the nn code and cd'ed into it)\n",
        "import network\n",
        "import mnist_loader\n",
        "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
        "training_data = list(training_data)\n",
        "test_data = list(test_data)\n"
      ],
      "metadata": {
        "id": "TY_GaewAIO1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.shape(training_data))\n",
        "print(np.shape(training_data[0][0]))\n",
        "print(np.shape(training_data[0][1]))\n",
        "print(training_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OCPyJhtQYtc",
        "outputId": "2915a568-5d5b-4d7b-b9d1-7ef44cdfa865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n",
            "(784, 1)\n",
            "(10, 1)\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average digit darkness\n",
        "# step 1 - write a function that can calculate the darkness of a single image\n",
        "def image_darkness(imgpixeldata):\n",
        "  darkness_total = 0\n",
        "  for x in imgpixeldata:\n",
        "    darkness_total = darkness_total + x\n",
        "  return darkness_total[0]\n",
        "\n",
        "# step 2 - call that function on all the training images and calculate the average darkness of each digit\n",
        "# There are 10 darkness totals because digits 0-9, which equals 10 in total, are from the MNIST data set.\n",
        "# Each digit has a darkness total that must be calculated seperately.\n",
        "\n",
        "darkness = image_darkness(training_data[0][0])\n",
        "whichimage = np.argmax(training_data[0][1])\n",
        "print(f\"The first image was a {whichimage} and its darkness was {darkness}\")\n",
        "darkness = image_darkness(training_data[1][0])\n",
        "whichimage = np.argmax(training_data[1][1])\n",
        "print(f\"The second image was a {whichimage} and its darkness was {darkness}\")\n",
        "\n",
        "# define a 10-element list of darkness totals\n",
        "darkness_totals = [0 for _ in range(10)]\n",
        "# define a 10-elment list of digit counts\n",
        "darkness_counts = [0 for _ in range(10)]\n",
        "\n",
        "# iterate through each image and update the two data structures\n",
        "for training_img in training_data:\n",
        "  darkness = image_darkness(training_img[0])\n",
        "  whichimage = np.argmax(training_img[1])\n",
        "  darkness_totals[whichimage] += darkness\n",
        "  darkness_counts[whichimage] += 1\n",
        "\n",
        "# now calculate the averages\n",
        "darkness_averages = [darkness_totals[i]/darkness_counts[i] for i in range(10)]\n",
        "\n",
        "print(darkness_counts)\n",
        "print(darkness_averages)\n",
        "\n",
        "# step 3 - use those averages to classify all the test data images and count how many of each digit you get right\n",
        "def find_closest(darkness, darkness_averages):\n",
        "  # add code here that determines which average was closest to darkness\n",
        "  return 0\n",
        "\n",
        "correct_counts = [0 for _ in range(10)]\n",
        "wrong_counts = [0 for _ in range(10)]\n",
        "\n",
        "for imgdata, whichimage in test_data:\n",
        "  darkness = image_darkness(imgdata)\n",
        "  # see which darkness_average is closest to \"darkness\" and make that our classification for this image\n",
        "  closest_digit = find_closest(darkness, darkness_averages)\n",
        "  if closest_digit == whichimage:\n",
        "    correct_counts[whichimage] += 1\n",
        "  else:\n",
        "    wrong_counts[whichimage] += 1\n",
        "\n",
        "# now that we have our correct/wrong counts, turn that into accuracies\n",
        "digit_accuracies = [correct_counts[i]/(correct_counts[i]+wrong_counts[i]) for i in range(10)]\n",
        "print(digit_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiMrbkucJPL9",
        "outputId": "9f66f024-cf54-4b55-89ea-e6ddfcfbdbfd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first image was a 5 and its darkness was 107.51953125\n",
            "The second image was a 0 and its darkness was 121.46484375\n",
            "[4932, 5678, 4968, 5101, 4859, 4506, 4951, 5175, 4842, 4988]\n",
            "[135.8691200324412, 59.66034750352237, 116.294303857186, 110.87092451235051, 95.22073970338548, 100.34646166222814, 107.38312020298929, 89.8788345410628, 117.88056410703221, 96.0455585592923]\n",
            "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(test_data))\n",
        "print(np.shape(test_data[0]))\n",
        "print(test_data[0][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRcQD33wRB1c",
        "outputId": "7fead165-7a48-40cf-842e-8ba94f20cfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 2)\n",
            "(2,)\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# part 2 - use this default configuration and the following hyper-parameters\n",
        "#    epochs - 30\n",
        "#    batch size - 10\n",
        "#    learning rate - 3.0\n",
        "net = network.Network([784, 30, 10])\n",
        "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3qm9cgIQ2rh",
        "outputId": "fd08c907-108b-4c69-c60f-7f6afa528b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 8958 / 10000\n",
            "Epoch 1 : 9271 / 10000\n",
            "Epoch 2 : 9337 / 10000\n",
            "Epoch 3 : 9359 / 10000\n",
            "Epoch 4 : 9376 / 10000\n",
            "Epoch 5 : 9367 / 10000\n",
            "Epoch 6 : 9411 / 10000\n",
            "Epoch 7 : 9385 / 10000\n",
            "Epoch 8 : 9413 / 10000\n",
            "Epoch 9 : 9407 / 10000\n",
            "Epoch 10 : 9437 / 10000\n",
            "Epoch 11 : 9442 / 10000\n",
            "Epoch 12 : 9455 / 10000\n",
            "Epoch 13 : 9456 / 10000\n",
            "Epoch 14 : 9442 / 10000\n",
            "Epoch 15 : 9470 / 10000\n",
            "Epoch 16 : 9450 / 10000\n",
            "Epoch 17 : 9462 / 10000\n",
            "Epoch 18 : 9451 / 10000\n",
            "Epoch 19 : 9453 / 10000\n",
            "Epoch 20 : 9444 / 10000\n",
            "Epoch 21 : 9467 / 10000\n",
            "Epoch 22 : 9455 / 10000\n",
            "Epoch 23 : 9485 / 10000\n",
            "Epoch 24 : 9473 / 10000\n",
            "Epoch 25 : 9462 / 10000\n",
            "Epoch 26 : 9476 / 10000\n",
            "Epoch 27 : 9492 / 10000\n",
            "Epoch 28 : 9462 / 10000\n",
            "Epoch 29 : 9485 / 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = net.feedforward(test_data[2][0])\n",
        "print(a)\n",
        "print(np.argmax(a))\n",
        "print(test_data[2][1])\n",
        "\n",
        "# per digit accuracies\n",
        "# loop through the test data again\n",
        "# calculate how many of each digit was classified correctly\n",
        "\n",
        "correct_counts = [0 for _ in range(10)]\n",
        "digit_counts = [0 for _ in range(10)]\n",
        "\n",
        "for (x, y) in test_data:\n",
        "  a = np.argmax(net.feedforward(x))\n",
        "  if a == y:\n",
        "    correct_counts[y] += 1\n",
        "  digit_counts[y] += 1\n",
        "\n",
        "print(correct_counts)\n",
        "print(digit_counts)\n",
        "accuracies = [correct_counts[i]/digit_counts[i] for i in range(10)]\n",
        "print(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPbCl_Rio5bK",
        "outputId": "bf22f8b5-6021-4514-a036-738c7df0067b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00560091e-13]\n",
            " [9.99068611e-01]\n",
            " [1.57520567e-05]\n",
            " [5.69105722e-06]\n",
            " [1.78291325e-11]\n",
            " [5.07502063e-07]\n",
            " [7.72172403e-06]\n",
            " [9.00642189e-10]\n",
            " [2.37304519e-06]\n",
            " [2.32996362e-10]]\n",
            "1\n",
            "1\n",
            "[956, 1119, 962, 950, 942, 813, 913, 980, 927, 923]\n",
            "[980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]\n",
            "[0.9755102040816327, 0.9859030837004406, 0.9321705426356589, 0.9405940594059405, 0.9592668024439919, 0.9114349775784754, 0.9530271398747391, 0.953307392996109, 0.9517453798767967, 0.9147670961347869]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " # creating the bar plot\n",
        "plt.bar(range(0,10), accuracies, color ='maroon',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Digit\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Per digit accuracy for standard hyperparams\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "T9P4DXeSBlAK",
        "outputId": "1f8375e9-395e-4002-88b5-fc89f41eb1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(net.weights[0]))\n",
        "print(net.weights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-adILgnNKqe9",
        "outputId": "96eaeffd-acde-4ba6-d96a-3207135cb3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 784)\n",
            "[[ 0.0215151  -0.04729249 -0.44721234 ... -1.97831409 -0.2865727\n",
            "   0.88160148]\n",
            " [ 2.36208788  0.6038336   0.20396425 ...  0.3926295  -0.86184143\n",
            "   0.64770832]\n",
            " [-1.14750678 -0.97593438  0.72427559 ... -0.4883032  -0.76593551\n",
            "   0.15989463]\n",
            " ...\n",
            " [ 0.4694041   0.03909368  0.36883623 ...  0.0452612   1.23588569\n",
            "   0.54394539]\n",
            " [-0.18138153  0.72164685  1.92287457 ...  0.25001934  1.10857264\n",
            "   1.29902218]\n",
            " [ 0.91300424  2.38522093 -0.11537195 ...  1.69392222 -0.48073141\n",
            "  -0.70233165]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(net.weights[1]))\n",
        "print(net.weights[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HFpBqj4MJWh",
        "outputId": "7164cdfd-31e0-41b0-8f52-367630b0bed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 30)\n",
            "[[ 3.67183713  2.35868514 -6.43078049  0.14005056  4.38970399  2.49434832\n",
            "  -0.40937287 -1.94369755  2.4259371   3.64487122 -7.53660691  1.8959186\n",
            "  -4.91148141  0.36191836  0.5634      2.27636407  0.52070603  3.62218105\n",
            "  -2.29334236 -3.18221871 -3.60816435 -1.38963331 -0.10855549 -4.1656265\n",
            "  -0.30824127 -1.09473708  5.64011432  1.44139839 -5.50467125  0.73341887]\n",
            " [-0.93112177  0.54200062 -3.31082687 -5.03686603 -1.76140692 -2.96273987\n",
            "   2.96767471  2.23596389 -1.86160948 -2.75913581 -2.86599827 -0.46055604\n",
            "   1.48191966 -0.24667187 -0.89017888 -5.6762719   1.42315355  2.7587841\n",
            "   2.94970173  2.63151541 -0.24542711 -2.73384039  1.53848519  6.3239753\n",
            "   5.65553213 -1.38490167 -1.53858687  1.20156804 -0.91376295  5.22033055]\n",
            " [ 1.39031944  1.30434834 -4.42748204  3.19220362  3.21947353  0.74491765\n",
            "   2.5373595   2.78566455 -3.53895725 -5.66059501 -3.35886548  1.62926675\n",
            "   1.06857464  0.34020818  2.83152287  0.30922755  0.3007657  -4.44173019\n",
            "  -3.32958078 -3.56633148  0.02465517  2.37606451 -0.56643158 -0.26128878\n",
            "   0.3635653  -3.92089197 -5.75595513 -7.1181647  -3.01172653 -3.74987543]\n",
            " [ 2.35221214 -1.70134881 -2.08602911 -5.1998961  -0.19924144 -0.96093644\n",
            "  -3.52665895 -2.50684866 -3.60574354  4.39049923 -8.01442627  4.41918583\n",
            "   2.54268291  0.58091245  7.24289881 -3.0534027  -1.2566122  -2.35274331\n",
            "   5.12859569 -4.83022954 -4.43846311  5.31626618  2.04709476 -6.20560786\n",
            "  -0.37540208  3.29746913 -1.0120991   4.23582558  2.64288324 -3.62656787]\n",
            " [-4.71461093 -3.88918773 -3.06246031 -3.25812625  0.20994025 -7.41883835\n",
            "   2.77640818 -3.61097046  1.44243532 -0.72526627 -2.82945319 -3.80410539\n",
            "  -6.84110821  2.79963391  4.69096344 -4.28739854  3.54387577 -1.62417257\n",
            "   1.90094554 -1.73790053  3.30852301  1.22775818 -2.9469831  -1.42429355\n",
            "  -5.43491133 -0.56420148  4.80613214  0.68595704 -0.93739484  2.0967038 ]\n",
            " [ 4.03063101 -1.74654099 -2.66102258 -2.23508937 -1.50707732  3.90464224\n",
            "  -1.513312   -2.99667434  3.59035159 -3.17471911 -1.44311241  1.05099613\n",
            "  -0.5308772  -0.11809071 -6.47946166  2.97580203  0.3449255  -2.59953637\n",
            "  -2.6528072   6.78461131 -7.9868097  -5.61242952  3.49419058 -1.33144967\n",
            "   0.58746448 -0.35616336 -1.39789791 -1.83529151 10.80503739  3.56990824]\n",
            " [-4.14467118 -2.56506885 -0.22761349  1.49785749  3.74983529 -3.10384064\n",
            "  -4.50262525  3.00792626  2.41013776  0.52699882 -7.92561429 -1.43251173\n",
            "   6.25649788 -0.48485712 -2.87656612  0.62179954  0.71500211  2.32876474\n",
            "   0.08606456 -0.82768529 -1.14152525  1.72116222 -1.70239722  1.40938529\n",
            "  -4.52133383  0.91347571  6.72478505  1.99484483  0.85346496  0.74025043]\n",
            " [ 0.867988    1.68981604  9.14865162  1.61649267 -3.66231257  3.05062467\n",
            "  -0.30021461 -6.20380083 -0.20390122 -2.12231511 -0.42731233 -4.69197396\n",
            "  -5.11399031 -1.46255755  1.59836947 -1.95735867  5.70418899  1.17731504\n",
            "   1.03226864 -2.23927169  0.74082757 -5.09940669 -3.68301611  0.77821778\n",
            "   0.12483353 -1.56246135 -6.30710386 -0.01172372 -2.53828584 -0.76077836]\n",
            " [-3.87916202  5.37284916 -4.51808239 -3.70890372 -6.34385107 -3.10505354\n",
            "  -3.50441119 -2.40960458  2.87222472 -2.51372748 -7.12955824  3.19043731\n",
            "  -2.0936279   1.05063958  4.81000325  2.36574079 -1.84929649 -0.26124896\n",
            "  -4.17007498 -6.26981972 -1.57915362  2.59163549 -5.64371555  1.44468794\n",
            "   0.58184587 -2.2459871   4.54612082 -0.11840696  2.05167618 -5.3961749 ]\n",
            " [-4.75567155 -2.62528245  3.21582393 -1.34816441  0.34753908 -0.45923227\n",
            "  -1.04207782  0.37157453 -2.03239142  0.80839746 -6.74635095 -4.97830236\n",
            "  -3.46574421  0.08249162  0.48867033  4.4002204  -7.96063939  0.24536253\n",
            "  -3.63954485  2.45820616 -3.21522108 -1.21976064  0.69047721 -2.27808929\n",
            "   6.09110381  2.35666788  7.51959596  0.03359961  0.48437017  0.45484395]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# part 3 - experiment with different hyper parameters\n",
        "# epochs - 5, 15, 30, 60 (batch size 10, learning 3.0),\n",
        "# batch - 5, 10, 50, 100 (epochs 30, learning 3.0),\n",
        "# learning rate - 1.0, 3.0, 5.0 (epochs 30, batch size 10),\n",
        "\n",
        "import time\n",
        "\n",
        "# Define the hyperparameters\n",
        "epochs = [5, 15, 30, 60]\n",
        "batch_sizes = [5, 10, 50, 100]\n",
        "learning_rates = [1.0, 3.0, 5.0]\n",
        "\n",
        "# Vary the number of training epochs\n",
        "for epoch in epochs:\n",
        "    start_time = time.time()\n",
        "    net = network.Network([784, 30, 10])\n",
        "    net.SGD(training_data, epoch, 10, 3.0, test_data=test_data)\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time for {epoch} epochs: {end_time - start_time} seconds\")\n",
        "\n",
        "# Vary the batch size\n",
        "for batch_size in batch_sizes:\n",
        "    start_time = time.time()\n",
        "    net = network.Network([784, 30, 10])\n",
        "    net.SGD(training_data, 30, batch_size, 3.0, test_data=test_data)\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time for batch size {batch_size}: {end_time - start_time} seconds\")\n",
        "\n",
        "# Vary the learning rate\n",
        "for learning_rate in learning_rates:\n",
        "    start_time = time.time()\n",
        "    net = network.Network([784, 30, 10])\n",
        "    net.SGD(training_data, 30, 10, learning_rate, test_data=test_data)\n",
        "    end_time = time.time()\n",
        "    print(f\"Training time for learning rate {learning_rate}: {end_time - start_time} seconds\")\n"
      ],
      "metadata": {
        "id": "hd3TYzZ9_d4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce49dbe-2dae-4cca-af3c-11b1a99b117b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 9047 / 10000\n",
            "Epoch 1 : 9226 / 10000\n",
            "Epoch 2 : 9272 / 10000\n",
            "Epoch 3 : 9317 / 10000\n",
            "Epoch 4 : 9331 / 10000\n",
            "Training time for 5 epochs: 58.06164789199829 seconds\n",
            "Epoch 0 : 8207 / 10000\n",
            "Epoch 1 : 8267 / 10000\n",
            "Epoch 2 : 8428 / 10000\n",
            "Epoch 3 : 8462 / 10000\n",
            "Epoch 4 : 8489 / 10000\n",
            "Epoch 5 : 8474 / 10000\n",
            "Epoch 6 : 8484 / 10000\n",
            "Epoch 7 : 8499 / 10000\n",
            "Epoch 8 : 8510 / 10000\n",
            "Epoch 9 : 8501 / 10000\n",
            "Epoch 10 : 8500 / 10000\n",
            "Epoch 11 : 8521 / 10000\n",
            "Epoch 12 : 8551 / 10000\n",
            "Epoch 13 : 8538 / 10000\n",
            "Epoch 14 : 8530 / 10000\n",
            "Training time for 15 epochs: 174.9431300163269 seconds\n",
            "Epoch 0 : 9109 / 10000\n",
            "Epoch 1 : 9207 / 10000\n",
            "Epoch 2 : 9312 / 10000\n",
            "Epoch 3 : 9304 / 10000\n",
            "Epoch 4 : 9352 / 10000\n",
            "Epoch 5 : 9350 / 10000\n",
            "Epoch 6 : 9333 / 10000\n",
            "Epoch 7 : 9363 / 10000\n",
            "Epoch 8 : 9411 / 10000\n",
            "Epoch 9 : 9401 / 10000\n",
            "Epoch 10 : 9435 / 10000\n",
            "Epoch 11 : 9437 / 10000\n",
            "Epoch 12 : 9437 / 10000\n",
            "Epoch 13 : 9422 / 10000\n",
            "Epoch 14 : 9427 / 10000\n",
            "Epoch 15 : 9447 / 10000\n",
            "Epoch 16 : 9440 / 10000\n",
            "Epoch 17 : 9469 / 10000\n",
            "Epoch 18 : 9460 / 10000\n",
            "Epoch 19 : 9473 / 10000\n",
            "Epoch 20 : 9461 / 10000\n",
            "Epoch 21 : 9452 / 10000\n",
            "Epoch 22 : 9456 / 10000\n",
            "Epoch 23 : 9442 / 10000\n",
            "Epoch 24 : 9457 / 10000\n",
            "Epoch 25 : 9488 / 10000\n",
            "Epoch 26 : 9477 / 10000\n",
            "Epoch 27 : 9490 / 10000\n",
            "Epoch 28 : 9474 / 10000\n",
            "Epoch 29 : 9488 / 10000\n",
            "Training time for 30 epochs: 346.8396611213684 seconds\n",
            "Epoch 0 : 9111 / 10000\n",
            "Epoch 1 : 9271 / 10000\n",
            "Epoch 2 : 9350 / 10000\n",
            "Epoch 3 : 9386 / 10000\n",
            "Epoch 4 : 9395 / 10000\n",
            "Epoch 5 : 9411 / 10000\n",
            "Epoch 6 : 9404 / 10000\n",
            "Epoch 7 : 9437 / 10000\n",
            "Epoch 8 : 9448 / 10000\n",
            "Epoch 9 : 9451 / 10000\n",
            "Epoch 10 : 9464 / 10000\n",
            "Epoch 11 : 9456 / 10000\n",
            "Epoch 12 : 9487 / 10000\n",
            "Epoch 13 : 9490 / 10000\n",
            "Epoch 14 : 9472 / 10000\n",
            "Epoch 15 : 9478 / 10000\n",
            "Epoch 16 : 9461 / 10000\n",
            "Epoch 17 : 9471 / 10000\n",
            "Epoch 18 : 9493 / 10000\n",
            "Epoch 19 : 9490 / 10000\n",
            "Epoch 20 : 9486 / 10000\n",
            "Epoch 21 : 9510 / 10000\n",
            "Epoch 22 : 9501 / 10000\n",
            "Epoch 23 : 9495 / 10000\n",
            "Epoch 24 : 9513 / 10000\n",
            "Epoch 25 : 9511 / 10000\n",
            "Epoch 26 : 9487 / 10000\n",
            "Epoch 27 : 9492 / 10000\n",
            "Epoch 28 : 9481 / 10000\n",
            "Epoch 29 : 9486 / 10000\n",
            "Epoch 30 : 9510 / 10000\n",
            "Epoch 31 : 9496 / 10000\n",
            "Epoch 32 : 9492 / 10000\n",
            "Epoch 33 : 9498 / 10000\n",
            "Epoch 34 : 9488 / 10000\n",
            "Epoch 35 : 9514 / 10000\n",
            "Epoch 36 : 9491 / 10000\n",
            "Epoch 37 : 9523 / 10000\n",
            "Epoch 38 : 9507 / 10000\n",
            "Epoch 39 : 9490 / 10000\n",
            "Epoch 40 : 9509 / 10000\n",
            "Epoch 41 : 9515 / 10000\n",
            "Epoch 42 : 9491 / 10000\n",
            "Epoch 43 : 9512 / 10000\n",
            "Epoch 44 : 9503 / 10000\n",
            "Epoch 45 : 9503 / 10000\n",
            "Epoch 46 : 9515 / 10000\n",
            "Epoch 47 : 9485 / 10000\n",
            "Epoch 48 : 9505 / 10000\n",
            "Epoch 49 : 9518 / 10000\n",
            "Epoch 50 : 9486 / 10000\n",
            "Epoch 51 : 9479 / 10000\n",
            "Epoch 52 : 9491 / 10000\n",
            "Epoch 53 : 9466 / 10000\n",
            "Epoch 54 : 9521 / 10000\n",
            "Epoch 55 : 9504 / 10000\n",
            "Epoch 56 : 9511 / 10000\n",
            "Epoch 57 : 9504 / 10000\n",
            "Epoch 58 : 9514 / 10000\n",
            "Epoch 59 : 9499 / 10000\n",
            "Training time for 60 epochs: 683.3314719200134 seconds\n",
            "Epoch 0 : 8165 / 10000\n",
            "Epoch 1 : 8363 / 10000\n",
            "Epoch 2 : 8414 / 10000\n",
            "Epoch 3 : 8428 / 10000\n",
            "Epoch 4 : 8448 / 10000\n",
            "Epoch 5 : 8485 / 10000\n",
            "Epoch 6 : 8513 / 10000\n",
            "Epoch 7 : 8423 / 10000\n",
            "Epoch 8 : 8522 / 10000\n",
            "Epoch 9 : 8452 / 10000\n",
            "Epoch 10 : 8532 / 10000\n",
            "Epoch 11 : 8541 / 10000\n",
            "Epoch 12 : 8539 / 10000\n",
            "Epoch 13 : 8548 / 10000\n",
            "Epoch 14 : 8559 / 10000\n",
            "Epoch 15 : 8579 / 10000\n",
            "Epoch 16 : 8572 / 10000\n",
            "Epoch 17 : 8570 / 10000\n",
            "Epoch 18 : 8542 / 10000\n",
            "Epoch 19 : 8547 / 10000\n",
            "Epoch 20 : 8634 / 10000\n",
            "Epoch 21 : 8655 / 10000\n",
            "Epoch 22 : 9439 / 10000\n",
            "Epoch 23 : 9518 / 10000\n",
            "Epoch 24 : 9504 / 10000\n",
            "Epoch 25 : 9534 / 10000\n",
            "Epoch 26 : 9506 / 10000\n",
            "Epoch 27 : 9489 / 10000\n",
            "Epoch 28 : 9486 / 10000\n",
            "Epoch 29 : 9517 / 10000\n",
            "Training time for batch size 5: 357.9886107444763 seconds\n",
            "Epoch 0 : 8294 / 10000\n",
            "Epoch 1 : 8426 / 10000\n",
            "Epoch 2 : 8413 / 10000\n",
            "Epoch 3 : 8489 / 10000\n",
            "Epoch 4 : 8506 / 10000\n",
            "Epoch 5 : 8532 / 10000\n",
            "Epoch 6 : 8577 / 10000\n",
            "Epoch 7 : 8560 / 10000\n",
            "Epoch 8 : 8549 / 10000\n",
            "Epoch 9 : 8567 / 10000\n",
            "Epoch 10 : 8562 / 10000\n",
            "Epoch 11 : 8594 / 10000\n",
            "Epoch 12 : 8556 / 10000\n",
            "Epoch 13 : 8574 / 10000\n",
            "Epoch 14 : 8591 / 10000\n",
            "Epoch 15 : 8587 / 10000\n",
            "Epoch 16 : 8587 / 10000\n",
            "Epoch 17 : 8616 / 10000\n",
            "Epoch 18 : 8594 / 10000\n",
            "Epoch 19 : 8619 / 10000\n",
            "Epoch 20 : 8574 / 10000\n",
            "Epoch 21 : 8605 / 10000\n",
            "Epoch 22 : 8615 / 10000\n",
            "Epoch 23 : 8601 / 10000\n",
            "Epoch 24 : 8611 / 10000\n",
            "Epoch 25 : 8618 / 10000\n",
            "Epoch 26 : 8654 / 10000\n",
            "Epoch 27 : 9493 / 10000\n",
            "Epoch 28 : 9485 / 10000\n",
            "Epoch 29 : 9502 / 10000\n",
            "Training time for batch size 10: 340.56422543525696 seconds\n",
            "Epoch 0 : 7564 / 10000\n",
            "Epoch 1 : 8561 / 10000\n",
            "Epoch 2 : 8949 / 10000\n",
            "Epoch 3 : 9086 / 10000\n",
            "Epoch 4 : 9135 / 10000\n",
            "Epoch 5 : 9193 / 10000\n",
            "Epoch 6 : 9224 / 10000\n",
            "Epoch 7 : 9237 / 10000\n",
            "Epoch 8 : 9267 / 10000\n",
            "Epoch 9 : 9287 / 10000\n",
            "Epoch 10 : 9315 / 10000\n",
            "Epoch 11 : 9315 / 10000\n",
            "Epoch 12 : 9334 / 10000\n",
            "Epoch 13 : 9330 / 10000\n",
            "Epoch 14 : 9350 / 10000\n",
            "Epoch 15 : 9371 / 10000\n",
            "Epoch 16 : 9371 / 10000\n",
            "Epoch 17 : 9364 / 10000\n",
            "Epoch 18 : 9393 / 10000\n",
            "Epoch 19 : 9377 / 10000\n",
            "Epoch 20 : 9392 / 10000\n",
            "Epoch 21 : 9397 / 10000\n",
            "Epoch 22 : 9390 / 10000\n",
            "Epoch 23 : 9385 / 10000\n",
            "Epoch 24 : 9404 / 10000\n",
            "Epoch 25 : 9416 / 10000\n",
            "Epoch 26 : 9410 / 10000\n",
            "Epoch 27 : 9411 / 10000\n",
            "Epoch 28 : 9422 / 10000\n",
            "Epoch 29 : 9424 / 10000\n",
            "Training time for batch size 50: 325.8336091041565 seconds\n",
            "Epoch 0 : 7212 / 10000\n",
            "Epoch 1 : 7777 / 10000\n",
            "Epoch 2 : 7963 / 10000\n",
            "Epoch 3 : 8083 / 10000\n",
            "Epoch 4 : 8152 / 10000\n",
            "Epoch 5 : 8195 / 10000\n",
            "Epoch 6 : 8229 / 10000\n",
            "Epoch 7 : 8258 / 10000\n",
            "Epoch 8 : 8271 / 10000\n",
            "Epoch 9 : 8300 / 10000\n",
            "Epoch 10 : 8310 / 10000\n",
            "Epoch 11 : 8333 / 10000\n",
            "Epoch 12 : 8354 / 10000\n",
            "Epoch 13 : 8346 / 10000\n",
            "Epoch 14 : 8369 / 10000\n",
            "Epoch 15 : 8376 / 10000\n",
            "Epoch 16 : 8381 / 10000\n",
            "Epoch 17 : 8390 / 10000\n",
            "Epoch 18 : 8395 / 10000\n",
            "Epoch 19 : 8388 / 10000\n",
            "Epoch 20 : 8403 / 10000\n",
            "Epoch 21 : 8412 / 10000\n",
            "Epoch 22 : 8427 / 10000\n",
            "Epoch 23 : 8423 / 10000\n",
            "Epoch 24 : 8439 / 10000\n",
            "Epoch 25 : 8433 / 10000\n",
            "Epoch 26 : 8434 / 10000\n",
            "Epoch 27 : 8442 / 10000\n",
            "Epoch 28 : 9225 / 10000\n",
            "Epoch 29 : 9287 / 10000\n",
            "Training time for batch size 100: 323.0034523010254 seconds\n",
            "Epoch 0 : 8758 / 10000\n",
            "Epoch 1 : 9064 / 10000\n",
            "Epoch 2 : 9154 / 10000\n",
            "Epoch 3 : 9216 / 10000\n",
            "Epoch 4 : 9274 / 10000\n",
            "Epoch 5 : 9283 / 10000\n",
            "Epoch 6 : 9321 / 10000\n",
            "Epoch 7 : 9328 / 10000\n",
            "Epoch 8 : 9357 / 10000\n",
            "Epoch 9 : 9305 / 10000\n",
            "Epoch 10 : 9389 / 10000\n",
            "Epoch 11 : 9379 / 10000\n",
            "Epoch 12 : 9389 / 10000\n",
            "Epoch 13 : 9389 / 10000\n",
            "Epoch 14 : 9401 / 10000\n",
            "Epoch 15 : 9395 / 10000\n",
            "Epoch 16 : 9420 / 10000\n",
            "Epoch 17 : 9425 / 10000\n",
            "Epoch 18 : 9435 / 10000\n",
            "Epoch 19 : 9422 / 10000\n",
            "Epoch 20 : 9437 / 10000\n",
            "Epoch 21 : 9413 / 10000\n",
            "Epoch 22 : 9433 / 10000\n",
            "Epoch 23 : 9443 / 10000\n",
            "Epoch 24 : 9426 / 10000\n",
            "Epoch 25 : 9445 / 10000\n",
            "Epoch 26 : 9444 / 10000\n",
            "Epoch 27 : 9467 / 10000\n",
            "Epoch 28 : 9455 / 10000\n",
            "Epoch 29 : 9446 / 10000\n",
            "Training time for learning rate 1.0: 337.15285778045654 seconds\n",
            "Epoch 0 : 9046 / 10000\n",
            "Epoch 1 : 9254 / 10000\n",
            "Epoch 2 : 9332 / 10000\n",
            "Epoch 3 : 9395 / 10000\n",
            "Epoch 4 : 9354 / 10000\n",
            "Epoch 5 : 9396 / 10000\n",
            "Epoch 6 : 9393 / 10000\n",
            "Epoch 7 : 9431 / 10000\n",
            "Epoch 8 : 9445 / 10000\n",
            "Epoch 9 : 9462 / 10000\n",
            "Epoch 10 : 9441 / 10000\n",
            "Epoch 11 : 9446 / 10000\n",
            "Epoch 12 : 9479 / 10000\n",
            "Epoch 13 : 9456 / 10000\n",
            "Epoch 14 : 9472 / 10000\n",
            "Epoch 15 : 9463 / 10000\n",
            "Epoch 16 : 9469 / 10000\n",
            "Epoch 17 : 9482 / 10000\n",
            "Epoch 18 : 9481 / 10000\n",
            "Epoch 19 : 9479 / 10000\n",
            "Epoch 20 : 9487 / 10000\n",
            "Epoch 21 : 9476 / 10000\n",
            "Epoch 22 : 9487 / 10000\n",
            "Epoch 23 : 9486 / 10000\n",
            "Epoch 24 : 9476 / 10000\n",
            "Epoch 25 : 9460 / 10000\n",
            "Epoch 26 : 9494 / 10000\n",
            "Epoch 27 : 9481 / 10000\n",
            "Epoch 28 : 9480 / 10000\n",
            "Epoch 29 : 9476 / 10000\n",
            "Training time for learning rate 3.0: 328.62692046165466 seconds\n",
            "Epoch 0 : 9112 / 10000\n",
            "Epoch 1 : 9240 / 10000\n",
            "Epoch 2 : 9275 / 10000\n",
            "Epoch 3 : 9272 / 10000\n",
            "Epoch 4 : 9358 / 10000\n",
            "Epoch 5 : 9381 / 10000\n",
            "Epoch 6 : 9388 / 10000\n",
            "Epoch 7 : 9415 / 10000\n",
            "Epoch 8 : 9390 / 10000\n",
            "Epoch 9 : 9440 / 10000\n",
            "Epoch 10 : 9406 / 10000\n",
            "Epoch 11 : 9451 / 10000\n",
            "Epoch 12 : 9450 / 10000\n",
            "Epoch 13 : 9430 / 10000\n",
            "Epoch 14 : 9463 / 10000\n",
            "Epoch 15 : 9442 / 10000\n",
            "Epoch 16 : 9462 / 10000\n",
            "Epoch 17 : 9451 / 10000\n",
            "Epoch 18 : 9486 / 10000\n",
            "Epoch 19 : 9469 / 10000\n",
            "Epoch 20 : 9431 / 10000\n",
            "Epoch 21 : 9501 / 10000\n",
            "Epoch 22 : 9412 / 10000\n",
            "Epoch 23 : 9493 / 10000\n",
            "Epoch 24 : 9476 / 10000\n",
            "Epoch 25 : 9479 / 10000\n",
            "Epoch 26 : 9458 / 10000\n",
            "Epoch 27 : 9479 / 10000\n",
            "Epoch 28 : 9439 / 10000\n",
            "Epoch 29 : 9455 / 10000\n",
            "Training time for learning rate 5.0: 329.02786684036255 seconds\n"
          ]
        }
      ]
    }
  ]
}